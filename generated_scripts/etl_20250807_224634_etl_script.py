import boto3
import pandas as pd
import logging
from snowflake.connector.pandas_tools import connect
from snowflake.connector import SnowflakeConnection
from snowflake.connector.errors import OperationalError, ProgrammingError

# Configuration dictionaries

# ===============================================================================
# CONFIGURATION INJECTION (Auto-generated by LangGraph workflow)
# ===============================================================================
import os

# Snowflake configuration (using actual environment variables)
SNOWFLAKE_CONFIG = {
    'account': os.getenv('SNOWFLAKE_ACCOUNT', 'WRCQQUY-IE42818'),
    'user': os.getenv('SNOWFLAKE_USER', 'PKN78'),
    'password': os.getenv('SNOWFLAKE_PASSWORD', 'your_password'),
    'warehouse': os.getenv('SNOWFLAKE_WAREHOUSE', 'COMPUTE_WH'),
    'database': os.getenv('SNOWFLAKE_DATABASE', 'dev_db'),
    'schema': os.getenv('SNOWFLAKE_SCHEMA', 'app_dm'),
}

# AWS configuration (using actual environment variables)
AWS_CONFIG = {
    'aws_access_key_id': os.getenv('AWS_ACCESS_KEY_ID'),
    'aws_secret_access_key': os.getenv('AWS_SECRET_ACCESS_KEY'),
    'region_name': os.getenv('AWS_REGION', 'us-east-1'),
}

# Validate configuration
def validate_snowflake_config():
    missing = [k for k, v in SNOWFLAKE_CONFIG.items() if not v or v.startswith('your_')]
    aws_missing = [k for k, v in AWS_CONFIG.items() if not v]
    
    if missing:
        print(f"⚠️  Missing Snowflake configuration: {', '.join(missing)}")
    if aws_missing:
        print(f"⚠️  Missing AWS configuration: {', '.join(aws_missing)}")
        
    if missing or aws_missing:
        print("Please set environment variables or update config.py")
        return False
    return True

# Check configuration on import
CONFIG_VALID = validate_snowflake_config()

# Print configuration status
if CONFIG_VALID:
    print("✅ Configuration validated successfully")
else:
    print("❌ Configuration validation failed - some operations may not work")

# ===============================================================================
# END OF CONFIGURATION INJECTION
# ===============================================================================

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ETLProcess:
    def __init__(self, aws_config, snowflake_config):
        self.s3_client = boto3.client('s3', **aws_config)
        self.snowflake_conn = connect(**snowflake_config)
        self.snowflake_cur = self.snowflake_conn.cursor()

        if not CONFIG_VALID:
            logger.error("Configuration is invalid or incomplete.")
            raise ValueError("Configuration is invalid or incomplete.")

    def download_file(self, bucket, key):
        try:
            s3_response = self.s3_client.get_object(Bucket=bucket, Key=key)
            data = s3_response['Body'].read().decode('utf-8')
            return data
        except Exception as e:
            logger.error(f"Error downloading file from S3: {e}")
            raise

    def parse_csv(self, csv_data):
        try:
            df = pd.read_csv(pd.compat.StringIO(csv_data))
            return df
        except Exception as e:
            logger.error(f"Error parsing CSV data: {e}")
            raise

    def validate_data_quality(self, df):
        if df.empty:
            logger.error("Dataframe is empty.")
            raise ValueError("Dataframe is empty.")
        if not all(col in df.columns for col in ['id', 'product_name', 'category', 'price', 'quantity', 'sale_date', 'customer_id', 'region']):
            logger.error("Missing columns in dataframe.")
            raise ValueError("Missing columns in dataframe.")
        if not df['id'].is_unique:
            logger.error("Duplicate id values found.")
            raise ValueError("Duplicate id values found.")

    def transform_data(self, df):
        df['sale_date'] = pd.to_datetime(df['sale_date'], errors='coerce')
        return df

    def load_to_snowflake(self, df):
        try:
            columns = ['id', 'product_name', 'category', 'price', 'quantity', 'sale_date', 'customer_id', 'region']
            for col in columns:
                df[col].fillna('', inplace=True)
            df.to_sql(
                name='sales_data',
                con=self.snowflake_conn,
                if_exists='replace',
                index=False,
                method='multi'
            )
        except (OperationalError, ProgrammingError) as e:
            logger.error(f"Error loading data to Snowflake: {e}")
            raise

    def execute(self):
        bucket = 'pkn-aws-genai'
        key = 'd30bf953-54be-414b-9ec7-f9e9944aa687.csv'
        
        try:
            csv_data = self.download_file(bucket, key)
            df = self.parse_csv(csv_data)
            self.validate_data_quality(df)
            df = self.transform_data(df)
            self.load_to_snowflake(df)
            logger.info("ETL process completed successfully.")
        except Exception as e:
            logger.error(f"ETL process failed: {e}")
            raise

if __name__ == "__main__":
    etl = ETLProcess(AWS_CONFIG, SNOWFLAKE_CONFIG)
    etl.execute()